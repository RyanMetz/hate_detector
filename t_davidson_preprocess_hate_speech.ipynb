{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "import string\n",
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as VS\n",
    "from textstat.textstat import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_hate = pd.read_csv('./hate-speech-and-offensive-language/data/labeled_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_hate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Unnamed\" is just a redundant index, \"count\" is the number of users who labeled a tweet, \"hate_speech\" \"offensive_language\" and \"neither\", are the number of votes a tweet got for each of those classes. \"Class\" is the final label assignment determined by majority vote. \"tweet\" is the text of each tweet. Because I only care about the text and the class I'm dropping the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_hate = raw_hate[['class', 'tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class     int64\n",
       "tweet    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_hate.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class    0\n",
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_hate.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24783, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_hate.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In \"class\" the values represent:\n",
    "0 - hate speech\n",
    "1 - offensive  language\n",
    "2 - neither"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class        3\n",
       "tweet    24783\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_hate.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_hate['class'].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19190\n",
       "2     4163\n",
       "0     1430\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_hate['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = raw_hate.tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "other_exclusions = [\"#ff\", \"ff\", \"rt\"]\n",
    "stopwords.extend(other_exclusions)\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "def preprocess(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, '', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, '', parsed_text)\n",
    "    return parsed_text\n",
    "\n",
    "def tokenize(tweet):\n",
    "    \"\"\"Removes punctuation & excess whitespace, sets to lowercase,\n",
    "    and stems tweets. Returns a list of stemmed tokens.\"\"\"\n",
    "    tweet = \" \".join(re.split(\"[^a-zA-Z]*\", tweet.lower())).strip()\n",
    "    tokens = [stemmer.stem(t) for t in tweet.split()]\n",
    "    return tokens\n",
    "\n",
    "def basic_tokenize(tweet):\n",
    "    \"\"\"Same as tokenize but without the stemming\"\"\"\n",
    "    tweet = \" \".join(re.split(\"[^a-zA-Z.,!?]*\", tweet.lower())).strip()\n",
    "    return tweet.split()\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=tokenize,\n",
    "    preprocessor=preprocess,\n",
    "    ngram_range=(1, 3),\n",
    "    stop_words=stopwords,\n",
    "    use_idf=True,\n",
    "    smooth_idf=False,\n",
    "    norm=None,\n",
    "    decode_error='replace',\n",
    "    max_features=10000,\n",
    "    min_df=5,\n",
    "    max_df=0.75\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct tfidf matrix and get relevant scores\n",
    "tfidf = vectorizer.fit_transform(tweets).toarray()\n",
    "vocab = {v:i for i, v in enumerate(vectorizer.get_feature_names())}\n",
    "idf_vals = vectorizer.idf_\n",
    "idf_dict = {i:idf_vals[i] for i in vocab.values()} #keys are indices; values are IDF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get POS tags for tweets and save as a string\n",
    "tweet_tags = []\n",
    "for t in tweets:\n",
    "    tokens = basic_tokenize(preprocess(t))\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    tag_list = [x[1] for x in tags]\n",
    "    tag_str = \" \".join(tag_list)\n",
    "    tweet_tags.append(tag_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can use the TFIDF vectorizer to get a token matrix for the POS tags\n",
    "pos_vectorizer = TfidfVectorizer(\n",
    "    tokenizer=None,\n",
    "    lowercase=False,\n",
    "    preprocessor=None,\n",
    "    ngram_range=(1, 3),\n",
    "    stop_words=None,\n",
    "    use_idf=False,\n",
    "    smooth_idf=False,\n",
    "    norm=None,\n",
    "    decode_error='replace',\n",
    "    max_features=5000,\n",
    "    min_df=5,\n",
    "    max_df=0.75,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct POS TF matrix and get vocab dict\n",
    "pos = pos_vectorizer.fit_transform(pd.Series(tweet_tags)).toarray()\n",
    "pos_vocab = {v:i for i, v in enumerate(pos_vectorizer.get_feature_names())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now get other features\n",
    "sentiment_analyzer = VS()\n",
    "\n",
    "def count_twitter_objs(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "    4) hashtags with HASHTAGHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned.\n",
    "    \n",
    "    Returns counts of urls, mentions, and hashtags.\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    hashtag_regex = '#[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n",
    "    parsed_text = re.sub(hashtag_regex, 'HASHTAGHERE', parsed_text)\n",
    "    return(parsed_text.count('URLHERE'),parsed_text.count('MENTIONHERE'),parsed_text.count('HASHTAGHERE'))\n",
    "\n",
    "def other_features(tweet):\n",
    "    \"\"\"This function takes a string and returns a list of features.\n",
    "    These include Sentiment scores, Text and Readability scores,\n",
    "    as well as Twitter specific features\"\"\"\n",
    "    sentiment = sentiment_analyzer.polarity_scores(tweet)\n",
    "    \n",
    "    words = preprocess(tweet) #Get text only\n",
    "    \n",
    "    syllables = textstat.syllable_count(words)\n",
    "    num_chars = sum(len(w) for w in words)\n",
    "    num_chars_total = len(tweet)\n",
    "    num_terms = len(tweet.split())\n",
    "    num_words = len(words.split())\n",
    "    avg_syl = round(float((syllables+0.001))/float(num_words+0.001),4)\n",
    "    num_unique_terms = len(set(words.split()))\n",
    "    \n",
    "    ###Modified FK grade, where avg words per sentence is just num words/1\n",
    "    FKRA = round(float(0.39 * float(num_words)/1.0) + float(11.8 * avg_syl) - 15.59,1)\n",
    "    ##Modified FRE score, where sentence fixed to 1\n",
    "    FRE = round(206.835 - 1.015*(float(num_words)/1.0) - (84.6*float(avg_syl)),2)\n",
    "    \n",
    "    twitter_objs = count_twitter_objs(tweet)\n",
    "    retweet = 0\n",
    "    if \"rt\" in words:\n",
    "        retweet = 1\n",
    "    features = [FKRA, FRE,syllables, avg_syl, num_chars, num_chars_total, num_terms, num_words,\n",
    "                num_unique_terms, sentiment['neg'], sentiment['pos'], sentiment['neu'], sentiment['compound'],\n",
    "                twitter_objs[2], twitter_objs[1],\n",
    "                twitter_objs[0], retweet]\n",
    "    #features = pandas.DataFrame(features)\n",
    "    return features\n",
    "\n",
    "def get_feature_array(tweets):\n",
    "    feats=[]\n",
    "    for t in tweets:\n",
    "        feats.append(other_features(t))\n",
    "    return np.array(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_features_names = [\"FKRA\", \"FRE\",\"num_syllables\", \"avg_syl_per_word\", \"num_chars\", \"num_chars_total\", \\\n",
    "                        \"num_terms\", \"num_words\", \"num_unique_words\", \"vader neg\",\"vader pos\",\"vader neu\", \\\n",
    "                        \"vader compound\", \"num_hashtags\", \"num_mentions\", \"num_urls\", \"is_retweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = get_feature_array(tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now join them all up\n",
    "feature_np_array = np.concatenate([tfidf,pos,feats],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally get a list of variable names\n",
    "variables = ['']*len(vocab)\n",
    "for k,v in vocab.items():\n",
    "    variables[v] = k\n",
    "\n",
    "pos_variables = ['']*len(pos_vocab)\n",
    "for k,v in pos_vocab.items():\n",
    "    pos_variables[v] = k\n",
    "\n",
    "feature_names = variables+pos_variables+other_features_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame(feature_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.to_csv('./hate-speech-and-offensive-language/data/feature_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.read_csv('./hate-speech-and-offensive-language/data/feature_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_hate.to_csv('./hate-speech-and-offensive-language/data/raw_hate_tweets_class.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_df\n",
    "y = raw_hate['class'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing more than one split so we can train on part of it, then make preds on the larger set, feed those to the NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.memory_usage(deep=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ipykernel_py3]",
   "language": "python",
   "name": "conda-env-ipykernel_py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
